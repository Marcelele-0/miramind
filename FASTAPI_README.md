# FastAPI Setup and Testing Guide

## Quick Start

1. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

2. **Set up environment variables:**

   - Copy `.env.example` to `.env`
   - Fill in your Azure Speech Service credentials:
     ```
     AZURE_SPEECH_ENDPOINT=https://your-region.api.cognitive.microsoft.com/
     AZURE_SPEECH_KEY=your-key-here
     AZURE_SPEECH_VOICE_NAME=en-US-JennyNeural
     OPENAI_API_KEY=your-openai-key-here
     ```

3. **Run the FastAPI server:**

   ```bash
   python run_server.py
   ```

   Or directly with uvicorn:

   ```bash
   uvicorn src.miramind.api.main:app --reload --host 0.0.0.0 --port 8000
   ```

4. **Test the API:**

   ```bash
   python test_api.py
   ```

5. **Test STT functionality:**

   ```bash
   python test_stt.py
   python test_voice_api.py
   ```

6. **Run the frontend:**
   ```bash
   cd src/miramind/frontend
   npm install
   npm run dev
   ```

## Features

### ðŸŽ¤ Voice Integration (NEW!)

- **Voice Input**: Users can record their voice directly in the browser
- **Speech-to-Text**: Real-time transcription using OpenAI Whisper
- **Voice Chat**: Complete voice-to-chatbot pipeline
- **Dual Mode**: Switch between text and voice input seamlessly

### ðŸ’¬ Text Chat

- Text-based conversation with the chatbot
- Chat history management
- Session tracking

### ðŸ”Š Audio Output

- Text-to-Speech responses
- Audio visualization
- Multiple audio format support

## API Endpoints

### Chat Endpoints

- `GET /api/test` - Test endpoint
- `POST /api/chat/start` - Initialize chat session
- `POST /api/chat/message` - Send chat message

### Voice Endpoints (NEW!)

- `POST /api/voice/upload` - Upload audio file for transcription
- `POST /api/voice/chat` - Complete voice-to-chat pipeline
- `POST /api/voice/record-and-transcribe` - Record and transcribe audio
- `POST /api/voice/start-recording` - Start recording session
- `POST /api/voice/stop-recording/{recording_id}` - Stop recording session

## Usage Guide

### Text Mode

1. Open `http://localhost:3000/call`
2. Click "Start a Call"
3. Select "Text" mode
4. Type your message and click "Send"

### Voice Mode (NEW!)

1. Open `http://localhost:3000/call`
2. Click "Start a Call"
3. Select "Voice" mode
4. Click "Start Recording" and speak your message
5. Click "Stop Recording" when done
6. The system will transcribe your speech and generate a response

## Troubleshooting

1. **No audio/response in frontend:**

   - Check if the API server is running on port 8000
   - Check browser console for errors
   - Verify that `/static/output.wav` is accessible
   - Check FastAPI logs for subprocess errors

2. **Voice recording issues:**

   - Ensure microphone permissions are granted
   - Check browser support for MediaRecorder API
   - Verify OPENAI_API_KEY is set correctly
   - Test with `python test_stt.py`

3. **Subprocess errors:**

   - Ensure Python environment has all required packages
   - Check that `run_chat.py` works standalone
   - Verify the working directory is set correctly

4. **Audio file not found:**

   - Check if the `frontend/public` directory exists
   - Verify audio file is being generated by the TTS service
   - Check static file mounting in FastAPI

5. **SSL Certificate issues (Windows):**
   - Run tests to check SSL configuration
   - The system will automatically handle malformed SSL_CERT_FILE paths

## Development

The main components are:

- **FastAPI API**: `src/miramind/api/main.py`
- **Chat Logic**: `src/miramind/llm/langgraph/run_chat.py`
- **Frontend**: `src/miramind/frontend/app/call/page.jsx`
- **STT Integration**: `src/miramind/audio/stt/`
- **Audio Utilities**: `src/miramind/frontend/lib/audioUtils.js`

## Documentation

- **STT Integration**: See `STT_README.md` for detailed voice functionality documentation
- **API Reference**: Check `/docs` endpoint when server is running (`http://localhost:8000/docs`)

## Testing

```bash
# Test basic functionality
python test_api.py

# Test STT components
python test_stt.py

# Test voice API endpoints
python test_voice_api.py
```
