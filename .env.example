# Azure Cognitive Services Speech Configuration
# Copy this file to .env and fill in your actual values

# Option 1: Using endpoint (recommended 2025 approach)
AZURE_SPEECH_ENDPOINT=https://YOUR_REGION.api.cognitive.microsoft.com/
AZURE_SPEECH_KEY=your_azure_speech_service_key_here

# Default voice settings
# Available voices: https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support#neural-voices
AZURE_SPEECH_VOICE_NAME=en-US-JennyNeural

# Example values:
# AZURE_SPEECH_ENDPOINT=https://eastus.api.cognitive.microsoft.com/
# AZURE_SPEECH_KEY=1234567890abcdef1234567890abcdef
# AZURE_SPEECH_VOICE_NAME=en-US-AriaNeural


#Azure OpenAi credentials
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT_URL=https://YOUR_RESOURCE.cognitiveservices.azure.com/
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

#Project directories
TESTS_DIR=your_tests_dir
LOGS_DIR=your_logs_dir
MIRAMIND_TEMP=project_temp_files_dir

#Models and model deployments
STT_MODEL="gpt-4o-transcribe"
LANGUAGE_DETECTION_DEPLOYMENT="o4-mini"

